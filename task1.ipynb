{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1afb32b1",
   "metadata": {},
   "source": [
    "# 任务1：\n",
    "微调在ImageNet上预训练的卷积神经网络实现Caltech-101分类\n",
    "\n",
    "基本要求：\n",
    "\n",
    "(1) 训练集测试集按照 [Caltech-101]( https://data.caltech.edu/records/mzrjq-6wc02) 标准；\n",
    "(2) 修改现有的 CNN 架构（如AlexNet，ResNet-18）用于 Caltech-101 识别，通过将其输出层大小设置为 101 以适应数据集中的类别数量，其余层使用在ImageNet上预训练得到的网络参数进行初始化；\n",
    "(3) 在 Caltech-101 数据集上从零开始训练新的输出层，并对其余参数使用较小的学习率进行微调；\n",
    "(4) 观察不同的超参数，如训练步数、学习率，及其不同组合带来的影响，并尽可能提升模型性能；\n",
    "(5) 与仅使用 Caltech-101 数据集从随机初始化的网络参数开始训练得到的结果 进行对比，观察预训练带来的提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef389948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b346f39",
   "metadata": {},
   "source": [
    "## 数据预处理，划分训练集、验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501db52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分完成！\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 原始数据集路径\n",
    "original_data_dir = \"101_ObjectCategories\"\n",
    "# 输出路径\n",
    "output_dir = \"caltech101_split\"\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "val_dir = os.path.join(output_dir, \"val\")\n",
    "test_dir = os.path.join(output_dir, \"test\")\n",
    "\n",
    "# 创建输出文件夹\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# 遍历每个类别文件夹\n",
    "for category in os.listdir(original_data_dir):\n",
    "    if category == 'BACKGROUND_Google':\n",
    "        continue  # 跳过背景文件夹\n",
    "    # 获取当前类别的路径\n",
    "    category_path = os.path.join(original_data_dir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        # 获取当前类别的所有图片路径\n",
    "        images = [os.path.join(category_path, img) for img in os.listdir(category_path) if img.endswith(('.jpg', '.png'))]\n",
    "        \n",
    "        # 按 70% 训练，15% 验证，15% 测试划分\n",
    "        train_images, temp_images = train_test_split(images, test_size=0.3, random_state=42)\n",
    "        val_images, test_images = train_test_split(temp_images, test_size=0.5, random_state=42)\n",
    "\n",
    "        # 创建类别文件夹\n",
    "        os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
    "        os.makedirs(os.path.join(val_dir, category), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n",
    "\n",
    "        # 移动图片到对应文件夹\n",
    "        for img in train_images:\n",
    "            shutil.copy(img, os.path.join(train_dir, category))\n",
    "        for img in val_images:\n",
    "            shutil.copy(img, os.path.join(val_dir, category))\n",
    "        for img in test_images:\n",
    "            shutil.copy(img, os.path.join(test_dir, category))\n",
    "\n",
    "print(\"数据集划分完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91149899",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"caltech101_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "428c20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Data Preparation\n",
    "batch_size = 32\n",
    "image_size = 224\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(root=f\"{data_dir}/val\", transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(root=f\"{data_dir}/test\", transform=data_transforms['val'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e34206",
   "metadata": {},
   "source": [
    "## Load Pretrained Model：ResNet-18\n",
    "微调并进行超参数选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5467db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验: lr=0.01, momentum=0.9, num_epochs=10\n",
      "512\n",
      "cuda:0\n",
      "Epoch 1/10, Train Loss: 1.4283, Val Loss: 0.4701, Val Acc: 0.8932\n",
      "Epoch 2/10, Train Loss: 0.3494, Val Loss: 0.2985, Val Acc: 0.9262\n",
      "Epoch 3/10, Train Loss: 0.2073, Val Loss: 0.2475, Val Acc: 0.9400\n",
      "Epoch 4/10, Train Loss: 0.1535, Val Loss: 0.2300, Val Acc: 0.9385\n",
      "Epoch 5/10, Train Loss: 0.1137, Val Loss: 0.2120, Val Acc: 0.9416\n",
      "Epoch 6/10, Train Loss: 0.0829, Val Loss: 0.1989, Val Acc: 0.9408\n",
      "Epoch 7/10, Train Loss: 0.0664, Val Loss: 0.1857, Val Acc: 0.9462\n",
      "Epoch 8/10, Train Loss: 0.0604, Val Loss: 0.1884, Val Acc: 0.9508\n",
      "Epoch 9/10, Train Loss: 0.0494, Val Loss: 0.1814, Val Acc: 0.9454\n",
      "Epoch 10/10, Train Loss: 0.0432, Val Loss: 0.1886, Val Acc: 0.9439\n",
      "实验: lr=0.01, momentum=0.95, num_epochs=10\n",
      "512\n",
      "cuda:0\n",
      "Epoch 1/10, Train Loss: 1.2438, Val Loss: 0.3966, Val Acc: 0.8978\n",
      "Epoch 2/10, Train Loss: 0.2305, Val Loss: 0.2375, Val Acc: 0.9347\n",
      "Epoch 3/10, Train Loss: 0.1347, Val Loss: 0.2432, Val Acc: 0.9354\n",
      "Epoch 4/10, Train Loss: 0.0726, Val Loss: 0.2026, Val Acc: 0.9400\n",
      "Epoch 5/10, Train Loss: 0.0470, Val Loss: 0.1809, Val Acc: 0.9531\n",
      "Epoch 6/10, Train Loss: 0.0413, Val Loss: 0.2032, Val Acc: 0.9362\n",
      "Epoch 7/10, Train Loss: 0.0338, Val Loss: 0.1871, Val Acc: 0.9477\n",
      "Epoch 8/10, Train Loss: 0.0275, Val Loss: 0.1685, Val Acc: 0.9493\n",
      "Epoch 9/10, Train Loss: 0.0214, Val Loss: 0.1830, Val Acc: 0.9485\n",
      "Epoch 10/10, Train Loss: 0.0171, Val Loss: 0.1657, Val Acc: 0.9516\n",
      "实验: lr=0.001, momentum=0.9, num_epochs=10\n",
      "512\n",
      "cuda:0\n",
      "Epoch 1/10, Train Loss: 3.0855, Val Loss: 2.1465, Val Acc: 0.6026\n",
      "Epoch 2/10, Train Loss: 1.7990, Val Loss: 1.3635, Val Acc: 0.7679\n",
      "Epoch 3/10, Train Loss: 1.1857, Val Loss: 0.9316, Val Acc: 0.8563\n",
      "Epoch 4/10, Train Loss: 0.8437, Val Loss: 0.7017, Val Acc: 0.8955\n",
      "Epoch 5/10, Train Loss: 0.6284, Val Loss: 0.5585, Val Acc: 0.9131\n",
      "Epoch 6/10, Train Loss: 0.5065, Val Loss: 0.4669, Val Acc: 0.9254\n",
      "Epoch 7/10, Train Loss: 0.4212, Val Loss: 0.4100, Val Acc: 0.9316\n",
      "Epoch 8/10, Train Loss: 0.3591, Val Loss: 0.3597, Val Acc: 0.9331\n",
      "Epoch 9/10, Train Loss: 0.3065, Val Loss: 0.3417, Val Acc: 0.9400\n",
      "Epoch 10/10, Train Loss: 0.2732, Val Loss: 0.3086, Val Acc: 0.9431\n",
      "实验: lr=0.001, momentum=0.95, num_epochs=10\n",
      "512\n",
      "cuda:0\n",
      "Epoch 1/10, Train Loss: 2.6557, Val Loss: 1.4048, Val Acc: 0.7410\n",
      "Epoch 2/10, Train Loss: 1.0806, Val Loss: 0.7108, Val Acc: 0.8878\n",
      "Epoch 3/10, Train Loss: 0.6081, Val Loss: 0.4531, Val Acc: 0.9277\n",
      "Epoch 4/10, Train Loss: 0.4020, Val Loss: 0.3567, Val Acc: 0.9324\n",
      "Epoch 5/10, Train Loss: 0.3005, Val Loss: 0.3055, Val Acc: 0.9377\n",
      "Epoch 6/10, Train Loss: 0.2394, Val Loss: 0.2678, Val Acc: 0.9424\n",
      "Epoch 7/10, Train Loss: 0.1949, Val Loss: 0.2438, Val Acc: 0.9431\n",
      "Epoch 8/10, Train Loss: 0.1623, Val Loss: 0.2219, Val Acc: 0.9508\n",
      "Epoch 9/10, Train Loss: 0.1462, Val Loss: 0.2188, Val Acc: 0.9416\n",
      "Epoch 10/10, Train Loss: 0.1245, Val Loss: 0.2074, Val Acc: 0.9485\n"
     ]
    }
   ],
   "source": [
    "# 超参数列表\n",
    "learning_rates = [0.01, 0.001]\n",
    "momentums = [0.9, 0.95]\n",
    "num_epochs_list = [10]\n",
    "\n",
    "\n",
    "# 遍历所有超参数组合\n",
    "for lr, momentum, num_epochs in itertools.product(learning_rates, momentums, num_epochs_list):\n",
    "    print(f\"实验: lr={lr}, momentum={momentum}, num_epochs={num_epochs}\")\n",
    "    # 模型和优化器\n",
    "    # Step 2: Load Pretrained Model\n",
    "    model = models.resnet18(pretrained=True)  # 加载 ResNet-18\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 101)  # 修改最后一层为 101 类\n",
    "    print(num_ftrs)\n",
    "    # Step 3: Freeze Parameters (微调其余参数)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "    # 仅为最后一层设置较大的学习率\n",
    "    # Step 4: Define Loss and Optimizer\n",
    "    optimizer = optim.SGD([\n",
    "        {'params': model.fc.parameters(), 'lr': lr},  # 最后一层使用较大的学习率\n",
    "        {'params': [param for name, param in model.named_parameters() if \"fc\" not in name], 'lr': 0.0001}  # 其余层使用较小的学习率\n",
    "    ], momentum=momentum)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        # Step 5: Training Loop\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(device)\n",
    "\n",
    "        # ...existing code...\n",
    "    writer = SummaryWriter(f\"runs/resnet/exp_lr{lr}_mom{momentum}_ep{num_epochs}\")\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "\n",
    "        # 验证集 loss 和 accuracy\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336f244",
   "metadata": {},
   "source": [
    "### 随机初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b15a9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 3.6639, Val Loss: 4.2416, Val Acc: 0.2475\n",
      "Epoch 2/10, Train Loss: 2.8497, Val Loss: 2.6851, Val Acc: 0.4174\n",
      "Epoch 3/10, Train Loss: 2.3866, Val Loss: 2.5757, Val Acc: 0.4427\n",
      "Epoch 4/10, Train Loss: 2.0714, Val Loss: 2.2823, Val Acc: 0.4804\n",
      "Epoch 5/10, Train Loss: 1.8297, Val Loss: 2.0167, Val Acc: 0.5250\n",
      "Epoch 6/10, Train Loss: 1.6034, Val Loss: 2.0346, Val Acc: 0.5204\n",
      "Epoch 7/10, Train Loss: 1.3896, Val Loss: 1.7018, Val Acc: 0.5757\n",
      "Epoch 8/10, Train Loss: 1.1804, Val Loss: 1.8173, Val Acc: 0.5780\n",
      "Epoch 9/10, Train Loss: 1.0334, Val Loss: 1.6412, Val Acc: 0.6011\n",
      "Epoch 10/10, Train Loss: 0.8914, Val Loss: 1.6070, Val Acc: 0.6218\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Compare with Random Initialization\n",
    "\n",
    "# 重新初始化模型（不加载预训练权重）\n",
    "random_model = models.resnet18(pretrained=False)  # 不加载预训练权重\n",
    "num_ftrs = random_model.fc.in_features\n",
    "random_model.fc = nn.Linear(num_ftrs, 101)  # 修改最后一层为 101 类\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(random_model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# 将模型移动到设备\n",
    "random_model = random_model.to(device)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 10\n",
    "writer = SummaryWriter(f\"runs/resnet_random/exp_lr{lr}_mom{momentum}_ep{num_epochs}\")\n",
    "for epoch in range(num_epochs):\n",
    "    random_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = random_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "# 验证集 loss 和 accuracy\n",
    "    random_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = random_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325cf29d",
   "metadata": {},
   "source": [
    "## Load Pretrained Model： AlexNet\n",
    "微调并进行超参数选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c928a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验: lr=0.01, momentum=0.9, num_epochs=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19057\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 1/10, Train Loss: 1.2685, Val Loss: 0.6792, Val Acc: 0.8378\n",
      "Epoch 2/10, Train Loss: 0.2640, Val Loss: 0.6221, Val Acc: 0.8493\n",
      "Epoch 3/10, Train Loss: 0.1215, Val Loss: 0.5896, Val Acc: 0.8678\n",
      "Epoch 4/10, Train Loss: 0.0800, Val Loss: 0.5784, Val Acc: 0.8724\n",
      "Epoch 5/10, Train Loss: 0.0578, Val Loss: 0.5915, Val Acc: 0.8647\n",
      "Epoch 6/10, Train Loss: 0.0472, Val Loss: 0.5844, Val Acc: 0.8755\n",
      "Epoch 7/10, Train Loss: 0.0299, Val Loss: 0.6044, Val Acc: 0.8762\n",
      "Epoch 8/10, Train Loss: 0.0221, Val Loss: 0.6240, Val Acc: 0.8709\n",
      "Epoch 9/10, Train Loss: 0.0274, Val Loss: 0.6241, Val Acc: 0.8632\n",
      "Epoch 10/10, Train Loss: 0.0298, Val Loss: 0.5957, Val Acc: 0.8762\n",
      "实验: lr=0.01, momentum=0.95, num_epochs=10\n",
      "cuda:0\n",
      "Epoch 1/10, Train Loss: 1.4452, Val Loss: 0.6685, Val Acc: 0.8324\n",
      "Epoch 2/10, Train Loss: 0.2942, Val Loss: 0.5648, Val Acc: 0.8632\n",
      "Epoch 3/10, Train Loss: 0.1170, Val Loss: 0.5378, Val Acc: 0.8762\n",
      "Epoch 4/10, Train Loss: 0.0864, Val Loss: 0.5619, Val Acc: 0.8716\n",
      "Epoch 5/10, Train Loss: 0.0791, Val Loss: 0.5846, Val Acc: 0.8739\n",
      "Epoch 6/10, Train Loss: 0.0504, Val Loss: 0.5564, Val Acc: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.0332, Val Loss: 0.5861, Val Acc: 0.8816\n",
      "Epoch 8/10, Train Loss: 0.0290, Val Loss: 0.5951, Val Acc: 0.8801\n",
      "Epoch 9/10, Train Loss: 0.0288, Val Loss: 0.5830, Val Acc: 0.8816\n",
      "Epoch 10/10, Train Loss: 0.0281, Val Loss: 0.5711, Val Acc: 0.8862\n",
      "实验: lr=0.001, momentum=0.9, num_epochs=10\n",
      "cuda:0\n",
      "Epoch 1/10, Train Loss: 1.4185, Val Loss: 0.5911, Val Acc: 0.8563\n",
      "Epoch 2/10, Train Loss: 0.3535, Val Loss: 0.5003, Val Acc: 0.8663\n",
      "Epoch 3/10, Train Loss: 0.1836, Val Loss: 0.4748, Val Acc: 0.8709\n",
      "Epoch 4/10, Train Loss: 0.1182, Val Loss: 0.5007, Val Acc: 0.8809\n",
      "Epoch 5/10, Train Loss: 0.0849, Val Loss: 0.4497, Val Acc: 0.8870\n",
      "Epoch 6/10, Train Loss: 0.0558, Val Loss: 0.4710, Val Acc: 0.8878\n",
      "Epoch 7/10, Train Loss: 0.0557, Val Loss: 0.4623, Val Acc: 0.8878\n",
      "Epoch 8/10, Train Loss: 0.0429, Val Loss: 0.4432, Val Acc: 0.8962\n",
      "Epoch 9/10, Train Loss: 0.0336, Val Loss: 0.4608, Val Acc: 0.8909\n",
      "Epoch 10/10, Train Loss: 0.0311, Val Loss: 0.4593, Val Acc: 0.8955\n",
      "实验: lr=0.001, momentum=0.95, num_epochs=10\n",
      "cuda:0\n",
      "Epoch 1/10, Train Loss: 1.3251, Val Loss: 0.5877, Val Acc: 0.8324\n",
      "Epoch 2/10, Train Loss: 0.2864, Val Loss: 0.5165, Val Acc: 0.8609\n",
      "Epoch 3/10, Train Loss: 0.1714, Val Loss: 0.4975, Val Acc: 0.8770\n",
      "Epoch 4/10, Train Loss: 0.0797, Val Loss: 0.5020, Val Acc: 0.8793\n",
      "Epoch 5/10, Train Loss: 0.0637, Val Loss: 0.4991, Val Acc: 0.8801\n",
      "Epoch 6/10, Train Loss: 0.0478, Val Loss: 0.5077, Val Acc: 0.8786\n",
      "Epoch 7/10, Train Loss: 0.0439, Val Loss: 0.4929, Val Acc: 0.8870\n",
      "Epoch 8/10, Train Loss: 0.0268, Val Loss: 0.4999, Val Acc: 0.8786\n",
      "Epoch 9/10, Train Loss: 0.0291, Val Loss: 0.4927, Val Acc: 0.8839\n",
      "Epoch 10/10, Train Loss: 0.0223, Val Loss: 0.5008, Val Acc: 0.8885\n"
     ]
    }
   ],
   "source": [
    "# 超参数列表\n",
    "learning_rates = [0.01, 0.001]\n",
    "momentums = [0.9, 0.95]\n",
    "num_epochs_list = [10]\n",
    "\n",
    "\n",
    "# 遍历所有超参数组合\n",
    "for lr, momentum, num_epochs in itertools.product(learning_rates, momentums, num_epochs_list):\n",
    "    print(f\"实验: lr={lr}, momentum={momentum}, num_epochs={num_epochs}\")\n",
    "    # 模型和优化器\n",
    "    # Step 2: Load Pretrained Model\n",
    "   # Step 2: Load Pretrained Model\n",
    "    model = models.alexnet(pretrained=True)  # 加载 AlexNet 预训练模型\n",
    "    num_ftrs = model.classifier[6].in_features  # 获取最后一层的输入特征数\n",
    "    model.classifier[6] = nn.Linear(num_ftrs, 101)  # 修改最后一层为 101 类\n",
    "    # Step 3: Freeze Parameters (微调其余参数)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True  # 解冻所有参数\n",
    "\n",
    "    # 仅为最后一层设置较大的学习率\n",
    "    # Step 4: Define Loss and Optimizer\n",
    "# 为最后一层设置较大的学习率，其余层设置较小的学习率\n",
    "    optimizer = optim.SGD([\n",
    "    {'params': model.classifier[6].parameters(), 'lr': lr},  # 最后一层\n",
    "    {'params': [param for name, param in model.named_parameters() if \"classifier.6\" not in name], 'lr': 0.0001}  # 其余层\n",
    "], momentum=momentum)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "        # Step 5: Training Loop\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(device)\n",
    "\n",
    "        # ...existing code...\n",
    "    writer = SummaryWriter(f\"runs/alexnet/exp_lr{lr}_mom{momentum}_ep{num_epochs}\")\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "\n",
    "        # 验证集 loss 和 accuracy\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c1d711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.2034, Val Loss: 3.8013, Val Acc: 0.1914\n",
      "Epoch 2/10, Train Loss: 3.5713, Val Loss: 3.4007, Val Acc: 0.2813\n",
      "Epoch 3/10, Train Loss: 3.2530, Val Loss: 3.1371, Val Acc: 0.3313\n",
      "Epoch 4/10, Train Loss: 2.9010, Val Loss: 2.8036, Val Acc: 0.3928\n",
      "Epoch 5/10, Train Loss: 2.5475, Val Loss: 2.4326, Val Acc: 0.4481\n",
      "Epoch 6/10, Train Loss: 2.3359, Val Loss: 2.3194, Val Acc: 0.4781\n",
      "Epoch 7/10, Train Loss: 2.0919, Val Loss: 2.1419, Val Acc: 0.5088\n",
      "Epoch 8/10, Train Loss: 1.9695, Val Loss: 2.0779, Val Acc: 0.5342\n",
      "Epoch 9/10, Train Loss: 1.8045, Val Loss: 1.9818, Val Acc: 0.5388\n",
      "Epoch 10/10, Train Loss: 1.6841, Val Loss: 2.0089, Val Acc: 0.5496\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Compare with Random Initialization\n",
    "\n",
    "# 重新初始化模型（不加载预训练权重）\n",
    "random_model = models.alexnet(pretrained=False)  # 不加载预训练权重\n",
    "num_ftrs = random_model.classifier[6].in_features\n",
    "random_model.classifier[6] = nn.Linear(num_ftrs, 101)  # 修改最后一层为 101 类\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(random_model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# 将模型移动到设备\n",
    "random_model = random_model.to(device)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 10\n",
    "writer = SummaryWriter(f\"runs/alexnet_random/exp_lr{lr}_mom{momentum}_ep{num_epochs}\")\n",
    "for epoch in range(num_epochs):\n",
    "    random_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = random_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "# 验证集 loss 和 accuracy\n",
    "    random_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = random_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
